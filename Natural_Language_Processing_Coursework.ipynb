{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPU/yoWCjdOTVfpipJ9+CJI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ScottHay14/Natural-Language-Processing-Coursework/blob/main/Natural_Language_Processing_Coursework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 1 - Dataset"
      ],
      "metadata": {
        "id": "e1FbPlkayA5I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Drug Reviews dataset from Druglib.com is a collection of patient reviews on specific drugs along with the related conditions. The dataset is broken up into these 9 variables.\n",
        "<br>\n",
        "<br>reviewID\n",
        "<br>urlDrugName\n",
        "<br>rating\n",
        "<br>effectiveness\n",
        "<br>sideEffects\n",
        "<br>condition\n",
        "<br>benefitsReview\n",
        "<br>sideEffectsReview\n",
        "<br>commentsReview\n",
        "<br>\n",
        "<br>\n",
        "The task going to be performed in my classwork is text classification with the goal of predicting drug effectivness ratings from the patients reviews. The effectiveness variable is categorical and contains 5 options of effectiveness these being Highly Effective, Considerably Effective, Moderately Effective, Marginally Effective, Ineffective.\n",
        "\n"
      ],
      "metadata": {
        "id": "YeUDDzlxjI9w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "2sX7fX0ilHsW"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading Data and combining the test and train dataset into one dataframe\n",
        "test_data = \"/content/Data/drugLibTest_raw.tsv\"\n",
        "train_data = \"/content/Data/drugLibTrain_raw.tsv\"\n",
        "\n",
        "test_df = pd.read_csv(test_data, delimiter=\"\\t\")\n",
        "train_df = pd.read_csv(train_data, delimiter=\"\\t\")\n",
        "\n",
        "df = pd.concat([test_df, train_df], ignore_index=True)"
      ],
      "metadata": {
        "id": "J5ziK43DuBzM"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exploring Data\n",
        "print(df.head()) # Just printing first rows to see if loaded correctly\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 805
        },
        "id": "Kvpt0etIu1hL",
        "outputId": "92ba9012-3368-4ca4-aebc-c72fdee96086"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0 urlDrugName  rating           effectiveness  \\\n",
            "0        1366      biaxin       9  Considerably Effective   \n",
            "1        3724    lamictal       9        Highly Effective   \n",
            "2        3824    depakene       4    Moderately Effective   \n",
            "3         969     sarafem      10        Highly Effective   \n",
            "4         696    accutane      10        Highly Effective   \n",
            "\n",
            "           sideEffects           condition  \\\n",
            "0    Mild Side Effects     sinus infection   \n",
            "1    Mild Side Effects    bipolar disorder   \n",
            "2  Severe Side Effects    bipolar disorder   \n",
            "3      No Side Effects  bi-polar / anxiety   \n",
            "4    Mild Side Effects        nodular acne   \n",
            "\n",
            "                                      benefitsReview  \\\n",
            "0  The antibiotic may have destroyed bacteria cau...   \n",
            "1  Lamictal stabilized my serious mood swings. On...   \n",
            "2  Initial benefits were comparable to the brand ...   \n",
            "3  It controlls my mood swings. It helps me think...   \n",
            "4  Within one week of treatment superficial acne ...   \n",
            "\n",
            "                                   sideEffectsReview  \\\n",
            "0                      Some back pain, some nauseau.   \n",
            "1  Drowsiness, a bit of mental numbness. If you t...   \n",
            "2  Depakene has a very thin coating, which caused...   \n",
            "3            I didnt really notice any side effects.   \n",
            "4  Side effects included moderate to severe dry s...   \n",
            "\n",
            "                                      commentsReview  \n",
            "0  Took the antibiotics for 14 days. Sinus infect...  \n",
            "1  Severe mood swings between hypomania and depre...  \n",
            "2  Depakote was prescribed to me by a Kaiser psyc...  \n",
            "3  This drug may not be for everyone but its wond...  \n",
            "4  Drug was taken in gelatin tablet at 0.5 mg per...  \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'str' object has no attribute 'value_counts'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3406877337.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Exploring Data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Just printing first rows to see if loaded correctly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0meffectiveness\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"effectiveness\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meffectiveness\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'value_counts'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Combining the 3 review categories into one (benefitsReview, sideEffectsReview, commentsReview) for both the training dataset and the testing dataset\n",
        "\n",
        "# Train dataset combined first\n",
        "train_df[\"combined_review\"] = train_df[\"benefitsReview\"].fillna(\"\").astype(str) + \"\\n\\n\" + train_df[\"sideEffectsReview\"].fillna(\"\").astype(str) + \"\\n\\n\" +  train_df[\"commentsReview\"].fillna(\"\").astype(str)\n",
        "x_train = train_df[\"combined_review\"].to_numpy()\n",
        "y_train = train_df[\"effectiveness\"].to_numpy()\n",
        "print(\"Train dataset example\")\n",
        "print(x_train[0][:1000])\n",
        "print(y_train[0])\n",
        "print(\"\\n\")\n",
        "\n",
        "# Test dataset combined after\n",
        "test_df[\"combined_review\"] = test_df[\"benefitsReview\"].fillna(\"\").astype(str) + \"\\n\\n\" + test_df[\"sideEffectsReview\"].fillna(\"\").astype(str) + \"\\n\\n\" +  test_df[\"commentsReview\"].fillna(\"\").astype(str)\n",
        "x_test = test_df[\"combined_review\"].to_numpy()\n",
        "y_test = test_df[\"effectiveness\"].to_numpy()\n",
        "print(\"Test dataset example\")\n",
        "print(x_test[0][:1000])\n",
        "print(y_test[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5hBUfZtWxKS",
        "outputId": "c9467d98-a7a6-4051-f299-b70eb6411007"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset example\n",
            "slowed the progression of left ventricular dysfunction into overt heart failure \r\r\n",
            "alone or with other agents in the managment of hypertension \r\r\n",
            "mangagement of congestive heart failur\n",
            "\n",
            "cough, hypotension , proteinuria, impotence , renal failure , angina pectoris , tachycardia , eosinophilic pneumonitis, tastes disturbances , anusease anorecia , weakness fatigue insominca weakness\n",
            "\n",
            "monitor blood pressure , weight and asses for resolution of fluid\n",
            "Highly Effective\n",
            "\n",
            "\n",
            "Test dataset example\n",
            "The antibiotic may have destroyed bacteria causing my sinus infection.  But it may also have been caused by a virus, so its hard to say.\n",
            "\n",
            "Some back pain, some nauseau.\n",
            "\n",
            "Took the antibiotics for 14 days. Sinus infection was gone after the 6th day.\n",
            "Considerably Effective\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing data\n",
        "import nltk\n",
        "\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"punkt_tab\")\n",
        "nltk.download(\"stopwords\")\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "\n",
        "def prep(X):\n",
        "  prep_text = []\n",
        "  for x in X:\n",
        "    token_text = word_tokenize(x)\n",
        "    normd_text = [token.lower() for token in token_text if token.isalpha()]\n",
        "    swr_text = [token for token in normd_text if token not in stopwords.words(\"english\")]\n",
        "    stemmer = SnowballStemmer(\"english\")\n",
        "    prep_text += [[stemmer.stem(word) for word in swr_text]]\n",
        "  prep_sentences = [\" \".join(sentence) for sentence in prep_text]\n",
        "  return prep_sentences\n",
        "\n",
        "prep_x_train = prep(x_train)\n",
        "prep_x_test = prep(x_test)\n",
        "\n",
        "print(\"Preprocessed working for train dataset\")\n",
        "print(prep_x_train[0][:1000])\n",
        "\n",
        "print(\"Preprocessed working for test dataset\")\n",
        "print(prep_x_test[0][:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOP-h3hwbMZy",
        "outputId": "8d1d90d8-ec56-4b37-837f-f66df0c28687"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessed working for train dataset\n",
            "although type birth control con pros help cramp also effect prevent pregnanc along use condom well heavi cycl cramp hot flash fatigu long last cycl month concid chang differ bc first time use kind bc unfortun due constant hassel happi result hate birth control would suggest anyon\n",
            "Preprocessed working for test dataset\n",
            "lamict stabil serious mood swing one minut claw wall pure mania next curl fetal posit bed contempl suicdi longer whim mood neither around lucki start pharmaceut almost immedi diagnos bipolar lamict give amaz clariti go day honest assess form real relationship lamitc lift fog guess could call medic realiz cloudi thought process use wonder feel interest hard dreamt begin lamict would dream mean dream sens abl imagin pictur scene asleep rem mayb everi two month dream everi night found closer take bedtim frequent intens dream drowsi bit mental numb take much feel sedat sinc abl clear honest assess emot thought determin much medic need tough found work perfect high dose less feel medicin wear prematur like last sleep sleep feel numb might call drowsi sluggish mind began treat bipolar disord use write fair amount fiction sort flow definit artist tempera lamict though inher creativ fizzl come spill deep manic euphoria work art someth requir disciplin field requir creativ expect see chang outp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 2 - Representation Learning"
      ],
      "metadata": {
        "id": "UXJvNSCPyG8K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "do later"
      ],
      "metadata": {
        "id": "jDToZ8ibigc_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install to get the Word2Vec to work\n",
        "!pip install gensim"
      ],
      "metadata": {
        "id": "te-cHNWijwyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "import numpy as np\n",
        "def word2vec_rep(sentence, w2v_model):\n",
        "  embs = [w2v_model.wv[word] for word in sentence if word in w2v_model.wv.index_to_key]\n",
        "  sent_emb = np.mean(np.array(embs), 0)\n",
        "  return sent_emb"
      ],
      "metadata": {
        "id": "CXV1C96LiiDV"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 3 - Algorithms"
      ],
      "metadata": {
        "id": "mDHwhU8-yPnK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 4 - Evaluation"
      ],
      "metadata": {
        "id": "5SXJoPQzyVUR"
      }
    }
  ]
}